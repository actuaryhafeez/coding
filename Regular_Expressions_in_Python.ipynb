{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regular Expressions in Python.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/actuaryhafeez/coding/blob/master/Regular_Expressions_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqlEaGAcVybM",
        "colab_type": "text"
      },
      "source": [
        "# Basic Concepts of String Manipulation\n",
        "\n",
        "# First day!\n",
        "Congratulations! It's your first day as a data scientist in the company! Your first project is to build a model for predicting if a movie will get a positive or negative review.\n",
        "You need to start exploring your dataset. In order to create a function that will scan each movie review, you want to know how many characters every string has and print the result out together with a statement that indicate what the number refers to. To test if your function works correctly, you are going to start by analyzing only one example.\n",
        "\n",
        "The text of one movie review has been already saved in the variable movie. You can use print(movie) to view the variable in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF57IdGWWCbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3a05296-873b-4194-dcdc-fec1bff78d8d"
      },
      "source": [
        "movie = 'fox and kelley soon become bitter rivals because the new fox books store is opening up right across the block from the small business .'; movie"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fox and kelley soon become bitter rivals because the new fox books store is opening up right across the block from the small business .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xjb7x2AVooI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpj0WkzPXCW9",
        "colab_type": "code",
        "outputId": "7afb6039-394c-4038-c4aa-07d6f71d4d2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Find characters in movie variable\n",
        "length_string = len(movie); length_string"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWrHhuJuXF-S",
        "colab_type": "code",
        "outputId": "d7252c4c-7bd5-43db-dd73-3bfe642738ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Convert to string\n",
        "to_string = str(length_string); to_string"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'135'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrqPDbxHXH_y",
        "colab_type": "code",
        "outputId": "18c846b2-b357-4404-e292-a4870678becc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Predefined variable\n",
        "statement = \"Number of characters in this review:\"; statement"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Number of characters in this review:'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuaC0DWkXJ2o",
        "colab_type": "code",
        "outputId": "a0f46bd2-c3ee-40d5-f527-73484b98d3f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Concatenate strings and print result\n",
        "print(statement+ \" \"+to_string)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of characters in this review: 135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6eROa0e9NFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d9ff163-dbe9-4e59-906b-57e9b664f98a"
      },
      "source": [
        "my_string = \"Awesome day\"; my_string"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Awesome day'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZX1s7WL9T5m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2de6b9a8-7596-40b8-d70d-6b1ca753b9cf"
      },
      "source": [
        "print(my_string[-1])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC6sc8m69ej3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d3a8e65-77b5-4a58-c4fa-c5817b4d12f4"
      },
      "source": [
        "print(my_string[0:3])\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Awe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJqmvufJ9nYQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cbb56ad9-2b2d-4ad7-ee01-c505c85c2981"
      },
      "source": [
        "print(my_string[::-1])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yad emosewA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RT8yIGe9yrh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f39c2b5-60eb-4304-9591-c9593d9c7707"
      },
      "source": [
        "my_string = \"tHis Is a niCe StriNg\"\n",
        "print(my_string.capitalize())\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a nice string\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVYN2hN7991i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "628f9e96-eddb-44e6-d402-157a45a2a3e2"
      },
      "source": [
        "my_string.split(sep=\" \", maxsplit=2)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tHis', 'Is', 'a niCe StriNg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KumLcxL6-Ohw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90535bd4-441e-4907-fbe5-470185883f25"
      },
      "source": [
        "my_string.rsplit(sep=\" \", maxsplit=2)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tHis Is a', 'niCe', 'StriNg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVlXoXG3-Wvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7486aae5-462a-4f43-e6f4-ec8a90bc40a0"
      },
      "source": [
        "my_string = \"This string will be split\\nin two\"\n",
        "print(my_string)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This string will be split\n",
            "in two\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f616zjxS-fcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cfca45cb-2227-42b2-dfea-d65d2ab3ce73"
      },
      "source": [
        "my_string = \"This string will be split\\nin two\"\n",
        "my_string.splitlines()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This string will be split', 'in two']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I5jKxuE-vtB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de7cee36-e8f2-4bda-a326-926a1194bfea"
      },
      "source": [
        "my_list = [\"this\", \"would\", \"be\", \"a\", \"string\"]\n",
        "print(\" \".join(my_list))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this would be a string\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TcK5o_--0lm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ead42e6-8ba4-4169-9b7f-bce129aba991"
      },
      "source": [
        "my_string = \" This string will be stripped\\n\"\n",
        "my_string.strip()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This string will be stripped'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQg4B5ky-89x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "efcd40ad-6a4f-4dea-c58b-c6a7680e7d6c"
      },
      "source": [
        "my_string = \" This string will be stripped\\n\"\n",
        "my_string.rstrip()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This string will be stripped\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeGxzkJL_Omj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b0753ea-2276-44a6-e5b9-d05012f19584"
      },
      "source": [
        "my_string.lstrip()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This string will be stripped\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqLiJC7e_R-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72e4d1d1-edc2-4bf2-ca5c-3939d1f9a2bd"
      },
      "source": [
        "my_string = \"Where's Waldo?\"\n",
        "my_string.find(\"Waldo\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKjDb2Ft_ccI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4fd8fcf-8261-4d87-901e-75f25d13aac2"
      },
      "source": [
        "my_string.find(\"Wenda\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTA22Udt_it-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25023d51-d52e-4148-9812-7e5f1d8d4b48"
      },
      "source": [
        "my_string = \"Where's Waldo?\"\n",
        "my_string.find(\"Waldo\", 0, 6)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATSJhT5vBOC2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e598c101-6025-44b5-88f2-be0dde0ea3dc"
      },
      "source": [
        "my_string = \"Where's Waldo?\"\n",
        "my_string.index(\"Waldo\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXw1JWV_BUi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8b40395-793b-4810-fe2e-3b9112d89713"
      },
      "source": [
        "my_string = \"Where's Waldo?\"\n",
        "try:\n",
        "  my_string.index(\"Wenda\")\n",
        "except ValueError:\n",
        "  print(\"Not found\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBPcNZ56Bg2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3de5ec4-6f11-4358-d138-783b0b9641f7"
      },
      "source": [
        "my_string = \"How many fruits do you have in your fruit basket?\"\n",
        "my_string.count(\"fruit\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_i1otatBk_f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdb5909b-682f-480b-dd97-88fb1873d956"
      },
      "source": [
        "my_string.count(\"fruit\", 0, 16)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT1y9qNLBqCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb014c23-de35-493e-947d-4ae35e084f60"
      },
      "source": [
        "my_string = \"The red house is between the blue house and the old house\"\n",
        "print(my_string.replace(\"house\", \"car\"))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The red car is between the blue car and the old car\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyawo3l-ByhR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7859ba33-9002-42f5-a6f2-77be47a3b438"
      },
      "source": [
        "print(my_string.replace(\"house\", \"car\", 2))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The red car is between the blue car and the old house\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FTH9S62hG2s",
        "colab_type": "text"
      },
      "source": [
        "**Artificial reviews**\n",
        "While checking out the movie reviews in your dataset, you realize that some of them show an atypical pattern. Since you should only include true reviews in your analysis, you decide to extract the suspicious ones that follow this pattern. You want to see if it is possible to artificially create reviews by using the first and last part of one example review and changing a keyword in the middle.\n",
        "\n",
        "The text of two movie reviews has been already saved in the variables **movie1 **and **movie2**. You can use the print() function to view the variables in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYynZLAzhQ-u",
        "colab_type": "code",
        "outputId": "a209a0f8-9812-441d-898b-b7d85897bf43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "movie1= 'the most significant tension of _election_ is the potential relationship between a teacher and his student .';movie1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the most significant tension of _election_ is the potential relationship between a teacher and his student .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NrHGbXoheYB",
        "colab_type": "code",
        "outputId": "ab69faec-ec24-4769-ed30-3782d8dc0297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "movie2= 'the most significant tension of _rushmore_ is the potential relationship between a teacher and his student .'; movie2"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the most significant tension of _rushmore_ is the potential relationship between a teacher and his student .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVd9G6S7hnLa",
        "colab_type": "code",
        "outputId": "4f6b975a-0b6f-4c28-a4d4-b3568a558f78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Select the first 32 characters of movie1\n",
        "first_part = movie1[:32]; first_part"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the most significant tension of '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wva3Q6dMhtkU",
        "colab_type": "code",
        "outputId": "e5e6abe7-0919-461b-f052-48fe217c7676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Select from 43rd character to the end of movie1\n",
        "last_part = movie1[42:]; last_part"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' is the potential relationship between a teacher and his student .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e3q2D1ZhxKZ",
        "colab_type": "code",
        "outputId": "856bcfc0-29a1-42cf-8096-181476f57d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Select from 33rd to the 42nd character\n",
        "middle_part = movie2[32:42]; middle_part"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'_rushmore_'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwKg6rlVhzTX",
        "colab_type": "code",
        "outputId": "36458f03-a06a-4693-a5a0-1eb67317f19c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Print concatenation and movie2 variable\n",
        "print(first_part+middle_part+last_part) \n",
        "print(movie2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the most significant tension of _rushmore_ is the potential relationship between a teacher and his student .\n",
            "the most significant tension of _rushmore_ is the potential relationship between a teacher and his student .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GPmZ7CEiNYg",
        "colab_type": "text"
      },
      "source": [
        "# Palindromes\n",
        "Next, you are committed to find any peculiarity in the words included in the movie review dataset. A palindrome is a sequence of characters which can be read the same backward as forward, for example: Madam or No lemon, no melon. You realize that there are some funny movie names that can have this characteristic. You want to make a list of all movie titles that are funny palindromes but you will start by analyzing one example.\n",
        "\n",
        "In python, you can also specify steps by using a third index. If you don't specify the first or second index and the third one is negative, it will return the characters jumping and backwards.\n",
        "\n",
        "The text of a movie review for one example has been already saved in the variable movie. You can use print(movie) to view the variable in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbf4zMX1lIur",
        "colab_type": "code",
        "outputId": "c160e26e-ca51-4644-e6f5-31e95c34bbd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "movie = 'oh my God! desserts I stressed was an ugly movie';movie"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'oh my God! desserts I stressed was an ugly movie'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDwN04CSiWSS",
        "colab_type": "code",
        "outputId": "60c6959e-3822-46ac-b177-77ee0078eca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get the word\n",
        "movie_title = movie[11:30]; movie_title"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'desserts I stressed'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91Or984IkSTU",
        "colab_type": "code",
        "outputId": "291a1296-d640-48b1-974a-02514071a5b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Obtain the palindrome\n",
        "palindrome = movie_title[::-1]; palindrome"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'desserts I stressed'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmiO2NVqkXPk",
        "colab_type": "code",
        "outputId": "bdf250f6-319a-4ff7-915b-edabeff60c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Print the word if it's a palindrome\n",
        "if movie_title == palindrome:\n",
        "\tprint(movie_title)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "desserts I stressed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upTe67Dpn13V",
        "colab_type": "text"
      },
      "source": [
        "# Normalizing reviews\n",
        "It's time to extract some important words present in your movie review dataset. First, you need to normalize them and then, count their frequency. Part of the normalization implies converting all the words to lowercase, removing special characters and extracting the root of a word so you count the variants as one.\n",
        "\n",
        "So imagine you have the following reviews: The movie surprises me very much and Marvel movies always surprise their audience. If you count the word frequency, you will count surprises one time and surprise one time. However, the verb surprise appears in both and its frequency should be two.\n",
        "\n",
        "The text of a movie review for only one example has been already saved in the variable movie. You can use print(movie) to view the variable in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUDHqcZyn5yG",
        "colab_type": "code",
        "outputId": "d224b7e8-584f-45ad-e8e6-57975238fb06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "movie = '$I supposed that coming from MTV Films I should expect no less$'; movie"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'$I supposed that coming from MTV Films I should expect no less$'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA6M4x6UoNNa",
        "colab_type": "code",
        "outputId": "282255de-a85f-4edd-be19-570066e322c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Convert to lowercase and print the result\n",
        "movie_lower = movie.lower()\n",
        "print(movie_lower)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "$i supposed that coming from mtv films i should expect no less$\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjbuMFUMoRH4",
        "colab_type": "code",
        "outputId": "84b2c65d-44e1-490b-b73d-5b13d7df4a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Remove whitespaces and print the result\n",
        "movie_no_space = movie_lower.strip(\"$\")\n",
        "print(movie_no_space)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i supposed that coming from mtv films i should expect no less\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6ItfkdaoXWR",
        "colab_type": "code",
        "outputId": "553fc713-3adc-449f-fc4d-04315462c7bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Split the string into substrings and print the result\n",
        "movie_split = movie_no_space.split()\n",
        "print(movie_split)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'supposed', 'that', 'coming', 'from', 'mtv', 'films', 'i', 'should', 'expect', 'no', 'less']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TapjHgyofjq",
        "colab_type": "code",
        "outputId": "792b2b9a-67af-47b0-ec4b-9cf3b5b4a518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Select root word and print the result\n",
        "word_root = movie_split[1][:-1]\n",
        "print(word_root)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "suppose\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJJJQ1qDpWZR",
        "colab_type": "text"
      },
      "source": [
        "# Time to join!\n",
        "While normalizing your text, you noticed that one review had a particular structure. This review ends with the HTML tag <\\i> and it has a lot of commas in different places of the sentence. You decide to remove the tag from the end and use the strategy of splitting the string and joining it back again without the commas.\n",
        "\n",
        "The text of a movie review has been already saved in the variable movie. You can use print(movie) to view the variable in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhLXkmShptC9",
        "colab_type": "code",
        "outputId": "5e365b97-c182-4907-f135-e318f97bf21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "movie =  'the film,however,is all good<\\\\i>'; movie"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the film,however,is all good<\\\\i>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhWb9FtspYNw",
        "colab_type": "code",
        "outputId": "586aece6-70dd-463c-997e-15b8eaa648ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Remove tags happening at the end and print results\n",
        "movie_tag = movie.rstrip(\"<\\i>\")\n",
        "print(movie_tag)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the film,however,is all good\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8loQp9npe4B",
        "colab_type": "code",
        "outputId": "ba3e02f0-0bb8-448c-edbc-ef6511007df3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Split the string using commas and print results\n",
        "movie_no_comma = movie_tag.split(\",\")\n",
        "print(movie_no_comma)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the film', 'however', 'is all good']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmFXpRefpg4N",
        "colab_type": "code",
        "outputId": "a6447d5d-c9de-4249-b452-edaf2dd01f76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Join back together and print results\n",
        "movie_join = \" \".join(movie_no_comma)\n",
        "print(movie_join)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the film however is all good\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81ASNYUn5iTi",
        "colab_type": "text"
      },
      "source": [
        "# Split lines or split the line?\n",
        "You are about to leave work when a colleague asks you to use your string manipulation skills to help him. You need to read strings from a file in a way that if the file contains strings on different lines, they are stored as separate elements. He also wants you to break the strings into pieces if you see that they contain commas.\n",
        "\n",
        "The text of the file has been already saved in the variable file. You can use print(file) to view the variable in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWlD4VdS5lbQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a85a6c31-36c4-46f1-99a9-a59ac7c25d9d"
      },
      "source": [
        "file = 'mtv films election, a high school comedy, is a current example\\nfrom there, director steven spielberg wastes no time, taking us into the water on a midnight swim'; file"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mtv films election, a high school comedy, is a current example\\nfrom there, director steven spielberg wastes no time, taking us into the water on a midnight swim'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hQODH0o6D8l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6bfba234-327d-4941-f312-b40beaf5486f"
      },
      "source": [
        "# Split string at line boundaries\n",
        "file_split = file.splitlines()\n",
        "\n",
        "# Print file_split\n",
        "print(file_split)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['mtv films election, a high school comedy, is a current example', 'from there, director steven spielberg wastes no time, taking us into the water on a midnight swim']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF7LUHa36NDP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "62906406-71bb-4e05-b415-9e6417d05a4f"
      },
      "source": [
        "# Complete for-loop to split by commas\n",
        "for substring in file_split:\n",
        "    substring_split = substring.split(\",\")\n",
        "    print(substring_split)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['mtv films election', ' a high school comedy', ' is a current example']\n",
            "['from there', ' director steven spielberg wastes no time', ' taking us into the water on a midnight swim']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkEaTHSSB_mx",
        "colab_type": "text"
      },
      "source": [
        "# Finding a substring\n",
        "It's a new day at work and you need to continue cleaning your dataset for the movie prediction project. While exploring the dataset, you notice a strange pattern: there are some repeated, consecutive words occurring between the character at position 37 and the character at position 41. You decide to write a function to find out which movie reviews show this peculiarity, remembering that the ending position you specify is not inclusive. If you detect the word, you also want to change the string by replacing it with only one instance of the word.\n",
        "\n",
        "Complete the if-else statement following the instructions.\n",
        "\n",
        "The text of three movie reviews has been already saved in the variable movies. You can use print(movies) to view the variable in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01471YCy6PFl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f2823cda-fce0-48bf-91ae-2e5a44cea6ec"
      },
      "source": [
        "dict = {200: \"it's clear that he's passionate about his beliefs , and that he's not just a punk looking for an excuse to beat people up .\",\n",
        "201: \"I believe you I always said that the actor actor actor is amazing in every movie he has played\",\n",
        "202: \"it's astonishing how frightening the actor actor norton looks with a shaved head and a swastika on his chest.\"}; dict"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{200: \"it's clear that he's passionate about his beliefs , and that he's not just a punk looking for an excuse to beat people up .\",\n",
              " 201: 'I believe you I always said that the actor actor actor is amazing in every movie he has played',\n",
              " 202: \"it's astonishing how frightening the actor actor norton looks with a shaved head and a swastika on his chest.\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSsszs2SDgKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "37ad0ec4-b7e8-4a60-d4fe-680665838238"
      },
      "source": [
        "import pandas as pd\n",
        "movies = pd.Series(dict); movies"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200    it's clear that he's passionate about his beli...\n",
              "201    I believe you I always said that the actor act...\n",
              "202    it's astonishing how frightening the actor act...\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUME-dyKWpPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "edf3d320-b48f-4047-bc78-5657f2e27391"
      },
      "source": [
        "for movie in movies:\n",
        "  \t# Find if actor occurrs between 37 and 41 inclusive\n",
        "    if movie.find(\"actor\", 37, 42) == -1:\n",
        "        print(\"Word not found\")\n",
        "    # Count occurrences and replace two by one\n",
        "    elif movie.count(\"actor\") == 2:  \n",
        "        print(movie.replace(\"actor actor\", \"actor\"))\n",
        "    else:\n",
        "        # Replace three occurrences by one\n",
        "        print(movie.replace(\"actor actor actor\", \"actor\"))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word not found\n",
            "I believe you I always said that the actor is amazing in every movie he has played\n",
            "it's astonishing how frightening the actor norton looks with a shaved head and a swastika on his chest.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g77kTHhDnf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict = {137: \"heck , jackie doesn't even have enough money for a haircut , looks like , much less a personal hairstylist .\",\n",
        " 138: \"in condor , chan plays the same character he's always played , himself , a mixture of bruce lee and tim allen , a master of both kung-fu and slapstick-fu .\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-HLgXlYXqUj",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOQuDhmMXvfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movies = pd.Series(dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaA9l7X4ZYjm",
        "colab_type": "text"
      },
      "source": [
        "# Where's the word?\n",
        "Before finishing cleaning your dataset, you want to check if a specific word occurs in the reviews. You noticed earlier a specific pattern in the strings. Now, you want to create a function to check if a word is present between characters with index 12, and 50, remembering that ending position is exclusive, and print out the lowest index where this word occurs. There are two methods to handle this situation. You want to see which one works best.\n",
        "\n",
        "The text of two movie reviews has been already saved in the variable movies. You can use print(movies) to view the variable in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffR2gmbRZPD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d8e85cb0-459e-4f97-ed4c-320d19da3296"
      },
      "source": [
        "for movie in movies:\n",
        "  try:\n",
        "    # Find the first occurrence of word\n",
        "  \tprint(movie.index('money', 12, 51))\n",
        "  except ValueError:\n",
        "    print(\"substring not found\")"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39\n",
            "substring not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4HTGUXOZkva",
        "colab_type": "text"
      },
      "source": [
        "# Replacing negations\n",
        "In order to keep working with your prediction project, your next task is to figure out how to handle negations that occur in your dataset. Some algorithms for prediction do not work well with negations, so a good way to handle this is to remove either not or n't, and to replace the next word by its antonym.\n",
        "\n",
        "Let's imagine that you have the string: The movie isn't good. You will need to remove n't and replace good for bad. This way, your string ends up being The movie is bad. You notice that in the first column of the dataset, you have a string that uses the word isn't followed by important.\n",
        "\n",
        "The text of this column has been already saved in the variable movies so you start working with it. You can use print(movies) to view it in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1MK5UofZpmt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d643a349-068d-45db-b03b-814f0160058c"
      },
      "source": [
        "movies = \"the rest of the story isn't important because all it does is serve as a mere backdrop for the two stars to share the screen .\";movies\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"the rest of the story isn't important because all it does is serve as a mere backdrop for the two stars to share the screen .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJw_LWoyZz5-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf5521ed-806b-4c4e-a250-94a295d0e619"
      },
      "source": [
        "# Replace negations \n",
        "movies_no_negation = movies.replace(\"isn't\", \"is\"); movies_no_negation\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the rest of the story is important because all it does is serve as a mere backdrop for the two stars to share the screen .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6eT2o1xZ-bo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01f19953-795e-4162-a2c2-392b5f02bdfd"
      },
      "source": [
        "\n",
        "# Replace important\n",
        "movies_antonym = movies_no_negation.replace(\"important\", \"insignificant\")\n",
        "\n",
        "# Print out\n",
        "print(movies_antonym)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the rest of the story is insignificant because all it does is serve as a mere backdrop for the two stars to share the screen .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcRhUL0bbWTD",
        "colab_type": "text"
      },
      "source": [
        "# Formatting Strings\n",
        "\n",
        "## Put it in order!\n",
        "Your company is analyzing the best way to provide users with different online courses. Your job is to scrape Wikipedia pages searching for tools used in Data Science subfields. You'll store the tool and field name in a database. After a text analysis, you realize that the information is provided in a specific position of the text but sometimes the field name is given first and the tool after that, while in other cases it's the other way around.\n",
        "\n",
        "You decide to use positional formatting to handle these situations because it provides a way to reorder placeholders.\n",
        "\n",
        "The text of one article has already been saved in the variable wikipedia_article. Also, the empty list my_list is already defined. You can use print() to view the variable in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmNmGBIsbcF4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c2ca82b5-4083-4881-ace0-4fe5a597664d"
      },
      "source": [
        "wikipedia_article= 'In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.';wikipedia_article"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd7yFsihcZ6c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "454d73c8-958a-4ef0-f459-58204a669279"
      },
      "source": [
        "# Assign the substrings to the variables\n",
        "first_pos = wikipedia_article[3:19].lower();first_pos"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'computer science'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iprlbgr3claO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1339d32-e0ad-43b9-9931-41846329bdec"
      },
      "source": [
        "second_pos = wikipedia_article[21:44].lower();second_pos"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'artificial intelligence'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS3ociBOgk4i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6b7effa0-c3af-4448-8808-1a89162c7124"
      },
      "source": [
        "my_list= []\n",
        "# Define string with placeholders \n",
        "my_list.append(\"The tool {} is used in {}\")\n",
        "\n",
        "# Define string with rearranged placeholders\n",
        "my_list.append(\"The tool {1} is used in {0}\")\n",
        "\n",
        "# Use format to print strings\n",
        "for my_string in my_list:\n",
        "  \tprint(my_string.format(first_pos, second_pos))"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tool computer science is used in artificial intelligence\n",
            "The tool artificial intelligence is used in computer science\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJftgvXKo-Jd",
        "colab_type": "text"
      },
      "source": [
        "# Calling by its name\n",
        "You have created your database with the tools and the different Data Science subfields they are used in. The company is considering creating courses using these tools and sending personalized emails to the users recommending the different topics. They have asked you to make this process more time-efficient. To do this, you want to create a template email with a standard message changing the different tools and corresponding field name.\n",
        "\n",
        "First, you want to try doing this with just one example as a proof of concept. You use positional formatting and named placeholders to call the variables in a dictionary.\n",
        "\n",
        "The variable courses containing one tool and one field name has been saved. You can use print(courses) to view the variable in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0EKjTQupB5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6b6f1db-a4e4-4d93-e22c-021f12c76b48"
      },
      "source": [
        "courses = ['artificial intelligence', 'neural networks']\n",
        "plan = {\n",
        "  \t\t\"field\": courses[0],\n",
        "        \"tool\": courses[1]\n",
        "        }\n",
        "\n",
        "# Complete the placeholders accessing elements of field and tool keys\n",
        "my_message = \"If you are interested in {data[field]}, you can take the course related to {data[tool]}\"\n",
        "\n",
        "# Use dictionary to replace placehoders\n",
        "print(my_message.format(data=plan))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "If you are interested in artificial intelligence, you can take the course related to neural networks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhiOSwzbponF",
        "colab_type": "text"
      },
      "source": [
        "# slides\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWl_JavYpkez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89612abd-f4f3-4a5b-fba0-3de2fe256a03"
      },
      "source": [
        "custom_string = \"String formatting\"\n",
        "print(f\"{custom_string} is a powerful technique\")"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "String formatting is a powerful technique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rws35WT0p9s4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25256d23-0e30-422d-b816-ac03b7a1201f"
      },
      "source": [
        "print(\"Machine learning provides {} the ability to learn {}\".format(\"systems\", \"automatically\"))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Machine learning provides systems the ability to learn automatically\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkh1cX7fo__g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c840b755-60d6-4006-a3f5-11f53b11694b"
      },
      "source": [
        "my_string = \"{} rely on {} datasets\"\n",
        "method = \"Supervised algorithms\"\n",
        "condition = \"labeled\"\n",
        "print(my_string.format(method, condition))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Supervised algorithms rely on labeled datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3Ls5-4UqMM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c74ef752-ec91-4db4-a72c-e0fc49d27fcf"
      },
      "source": [
        "print(\"{} has a friend called {} and a sister called {}\".format(\"Betty\", \"Linda\", \"Daisy\"))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Betty has a friend called Linda and a sister called Daisy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18_oiuBxqRmX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "822c9267-a14b-41b9-a643-e62af72b3e36"
      },
      "source": [
        "print(\"{2} has a friend called {0} and a sister called {1}\".format(\"Betty\", \"Linda\", \"Daisy\"))"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Daisy has a friend called Betty and a sister called Linda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ91d_ltqVFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87830ccb-2739-48a0-ce5b-ce5dec1aa377"
      },
      "source": [
        "tool=\"Unsupervised algorithms\"\n",
        "goal=\"patterns\"\n",
        "print(\"{title} try to find {aim} in the dataset\".format(title=tool, aim=goal))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unsupervised algorithms try to find patterns in the dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNa6eX1UqcBM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79c94ae7-3a38-4820-a1e4-2b2d9b9da505"
      },
      "source": [
        "print(\"Only {0:f}% of the {1} produced worldwide is {2}!\".format(0.5155675, \"data\", \"analyzed\"))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Only 0.515567% of the data produced worldwide is analyzed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f625paipqg3V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78509315-eb7d-42b3-a123-b8f989cbbd7e"
      },
      "source": [
        "print(\"Only {0:.2f}% of the {1} produced worldwide is {2}!\".format(0.5155675, \"data\", \"analyzed\"))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Only 0.52% of the data produced worldwide is analyzed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYJomZkkqlOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f96dfff2-73ab-4251-d328-b0ea9fceeaa4"
      },
      "source": [
        "from datetime import datetime\n",
        "print(datetime.now())\n"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-23 12:10:42.228039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZElazEu2qqg-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26cde599-e60d-4474-e9ea-ddfbaf45cb4b"
      },
      "source": [
        "print(\"Today's date is {:%Y-%m-%d %H:%M}\".format(datetime.now()))\n"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Today's date is 2019-12-23 12:21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuinNDCytLCZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18d11171-1ba8-4937-8919-328eb396d45a"
      },
      "source": [
        "way = \"code\"\n",
        "method = \"learning Python faster\"\n",
        "print(f\"Practicing how to {way} is the best method for {method}\")"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Practicing how to code is the best method for learning Python faster\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2PEwNcrvtvv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d78e1b2-04d2-446a-cb3f-2632e51dbf20"
      },
      "source": [
        "name = \"Python\"\n",
        "print(f\"Python is called {name!r} due to a comedy series\")\n"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python is called 'Python' due to a comedy series\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdWZJZ-bv0yj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33604ca1-1ad4-47fb-ca96-4ee36d0b11ad"
      },
      "source": [
        "number = 90.41890417471841\n",
        "print(f\"In the last 2 years, {number:.2f}% of the data was produced worldwide!\")\n"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In the last 2 years, 90.42% of the data was produced worldwide!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r9jXfyJv7Rd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2339997a-9a60-482a-8fb6-49a14f2dbde5"
      },
      "source": [
        "from datetime import datetime\n",
        "my_today = datetime.now()\n",
        "print(f\"Today's date is {my_today:%B %d, %Y}\")"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Today's date is December 23, 2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toAVaHP3wH7H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3dc5d4c-79a2-488f-e8dd-97d83f29ac1b"
      },
      "source": [
        "family = {\"dad\": \"John\", \"siblings\": \"Peter\"}\n",
        "print(\"Is your dad called {family[dad]}?\".format(family=family))"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is your dad called John?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHfH6VnBwPK0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c03176d0-366b-4788-de90-bc5a1467c827"
      },
      "source": [
        "print(f\"Is your dad called {family['dad']}?\")"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is your dad called John?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKLlsLM1wiDB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da84d795-dade-4488-cb9a-0ac7a3f4f957"
      },
      "source": [
        "family = {\"dad\": \"John\", \"siblings\": \"Peter\"}\n",
        "print(f\"Is your dad called {family['dad']}?\")"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is your dad called John?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPSV_rOawQxX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a195cd2-7c93-4f6f-f7e7-c9174f370d02"
      },
      "source": [
        "my_number = 4\n",
        "my_multiplier = 7\n",
        "print(f'{my_number} multiplied by {my_multiplier} is {my_number * my_multiplier}')"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 multiplied by 7 is 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CATG2gZdwztH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_function(a, b):\n",
        "  return a + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayH7ndkew-WV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2508ffbd-82d4-4e24-f6af-cfee53819e6b"
      },
      "source": [
        "print(f\"If you sum up 10 and 20 the result is {my_function(10, 20)}\")"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "If you sum up 10 and 20 the result is 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJraJ1Lzw4WJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c07da20b-75c3-4ff5-ea3d-50bc603e2370"
      },
      "source": [
        "from string import Template\n",
        "my_string = Template('Data science has been called $identifier')\n",
        "my_string.substitute(identifier=\"sexiest job of the 21st century\")"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Data science has been called sexiest job of the 21st century'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0HWwOS6xFJ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdf7fc08-8343-4245-aa5c-c3879ece7300"
      },
      "source": [
        "from string import Template\n",
        "job = \"Data science\"\n",
        "name = \"sexiest job of the 21st century\"\n",
        "my_string = Template('$title has been called $description')\n",
        "my_string.substitute(title=job, description=name)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Data science has been called sexiest job of the 21st century'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmYOMmMyxI7L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a08ee3cc-fd0b-4c19-bf10-32af87ddd55f"
      },
      "source": [
        "my_string = Template('I find Python very ${noun}ing but my sister has lost $noun')\n",
        "my_string.substitute(noun=\"interest\")"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I find Python very interesting but my sister has lost interest'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lg1HRH-xMtn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44060f53-d34c-4e4f-d7f3-e0d310c4d59b"
      },
      "source": [
        "my_string = Template('I paid for the Python course only $$ $price, amazing!')\n",
        "my_string.substitute(price=\"12.50\")"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I paid for the Python course only $ 12.50, amazing!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnOdzQ8xxy5k",
        "colab_type": "text"
      },
      "source": [
        "# What day is today?\n",
        "It's lunch time and you are talking with some of your colleagues. They comment that they feel that every morning someone should send them a reminder of what day it is so they can check in the calendar what their assignments are for that day.\n",
        "\n",
        "You want to help out and decide to write a small script that takes the date and time of the day so that every morning, a message is sent to your colleagues. You remember that you can use the module datetime along with named placeholders to achieve your goal.\n",
        "\n",
        "The date should be expressed as April 16, 2019 and the time as 16:30.\n",
        "\n",
        "You write down some specifiers to help you: %d(day), %B (month name), %m (month number), %Y(year), %H (hour) and %M(minutes)\n",
        "\n",
        "You can use the IPython Shell to explore the module datetime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV1PZfJVx1dX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0aad3a1-6a0f-4b7d-a3d5-62bf95207f39"
      },
      "source": [
        "# Import datetime \n",
        "from datetime import datetime\n",
        "\n",
        "# Assign date to get_date\n",
        "get_date = datetime.now()\n",
        "\n",
        "# Add named placeholders with format specifiers\n",
        "message = \"Good morning. Today is {today:%B %d, %Y}. It's {today:%H:%M} ... time to work!\"\n",
        "\n",
        "# Format date\n",
        "print(message.format(today= get_date))"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Good morning. Today is December 23, 2019. It's 12:43 ... time to work!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAD65LweyNVT",
        "colab_type": "text"
      },
      "source": [
        "# Literally formatting\n",
        "While analyzing the text from Wikipedia pages, you read that Python 3.6 introduced f-strings.\n",
        "\n",
        "You remember that you've created a website that displayed data science facts but it was too slow. You think that it could be due to the string formatting you used. Because f-strings are very fast and easy to use, you decide to rewrite that project.\n",
        "\n",
        "The variables field1, field2 and field3 containing character strings as well as the numeric variables fact1, fact2, fact3 and fact4 have been saved.\n",
        "\n",
        "If you want to explore the variables, you can use print() to view them in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aIS7htxyPSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "field1 = 'sexiest job'\n",
        "field2 = 'data is produced daily'\n",
        "field3 = 'Individuals'\n",
        "fact1 = 21\n",
        "fact2 = 2500000000000000000\n",
        "fact3 = 72.41415415151\n",
        "fact4 = 1.09"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOdaqvK61U47",
        "colab_type": "text"
      },
      "source": [
        "!s (string version)\n",
        "\n",
        "!r (string containing a printable representation, i.e. with quotes)\n",
        "\n",
        "!a (some that !r but escape the non-ASCII characters)\n",
        "\n",
        "e (scientic notation, e.g. 5 10^3)\n",
        "\n",
        "d (digit, e.g. 4)\n",
        "\n",
        "f (oat, e.g. 4.5353)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GptSRrn0q4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3520c3b8-7ece-4755-f84b-0e2f9a6d315f"
      },
      "source": [
        "# Complete the f-string (Complete the f-string to include the variable field1 with quotes and the variable fact1 as a digit.)\n",
        "print(f\"Data science is considered {field1!r} in the {field1}st century\")"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data science is considered 'sexiest job' in the sexiest jobst century\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y48Rj0y-1jRv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd23e4e7-a7cb-4612-a480-c1c52ec800a8"
      },
      "source": [
        "# Complete the f-string to include the the variable fact2 using exponential notation, and the variable field2\n",
        "print(f\"About {fact2:e} of field2 in the world\")"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "About 2.500000e+18 of field2 in the world\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0JmQ3440-zB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba8185eb-d662-4945-ed3d-3f3f9cd292b2"
      },
      "source": [
        "# Complete the f-string to include field3 together with fact3 rounded to 2 decimals, and fact4 rounded to one decimal.\n",
        "print(f\"{field3} create around {fact3:.2f}% of the data but only {fact4:.1f}% is analyzed\")\n"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Individuals create around 72.41% of the data but only 1.1% is analyzed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiZVY8sbAtXy",
        "colab_type": "text"
      },
      "source": [
        "# Make this function\n",
        "Wow! You are excited to see how fast and easy f-strings worked. So you plan to rewrite some more of your old code.\n",
        "\n",
        "Now you know that f-strings allow you to evaluate expressions where they appear and include function and method calls. You decide to use them in a project where you analyze 120 tweets to check if they include links to different news. In that way, you expect the code to be cleaner and more readable.\n",
        "\n",
        "The variables number1, number2,string1, and list_links have already been pre-loaded.\n",
        "\n",
        "If you want to explore the variables, you can use print() to view them in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj-c7nzt2iMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number1 = 120\n",
        "number2 = 7\n",
        "string1= 'httpswww.datacamp.com'\n",
        "list_links = ['www.news.com',\n",
        " 'www.google.com',\n",
        " 'www.yahoo.com',\n",
        " 'www.bbc.com',\n",
        " 'www.msn.com',\n",
        " 'www.facebook.com',\n",
        " 'www.news.google.com']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxw_toYA3v1p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cf0fce3-cc22-4012-bf97-cac7637031f1"
      },
      "source": [
        "# Inside the f-string, include number1,number2 and the result of dividing number1 by number2 rounded to one decimal.\n",
        "print(f\"{number1} tweets were downloaded in {number2} minutes indicating a speed of {number1/number2:.1f} tweets per min\")"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120 tweets were downloaded in 7 minutes indicating a speed of 17.1 tweets per min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nuwcAU94Bjb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48527b47-cbae-4a15-8b91-36422077dce4"
      },
      "source": [
        "# Inside the f-string, get list_links length, multiply it by 100 and divide it by 120. Round the result to two decimals.\n",
        "print(f\"Only {(len(list_links)*100/120):.2f}% of the posts contain links\")"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Only 5.83% of the posts contain links\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCil2Wj484t_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d65dbc2-bc32-48e1-caab-7f33175d4a1a"
      },
      "source": [
        "# Inside the f-string, use .replace() to replace the substring https with an empty substring in string1\n",
        "print(f\"{string1.replace('https', '')}\")"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "www.datacamp.com\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rR5HFPTAhWU",
        "colab_type": "text"
      },
      "source": [
        "# On time\n",
        "Lastly, you want to rewrite an old real estate prediction project. At the time, you obtained historical information about house prices and used it to make a prediction on future values.\n",
        "\n",
        "The date was in the datetime format: datetime.datetime(1990, 3, 17) but to print it out, you format it as 3-17-1990. You also remember that you defined a dictionary for each neighborhood. Now, you believe that you can handle both type of data better with f-strings.\n",
        "\n",
        "Two dictionaries, east and west, both with the keys date and price, have already been loaded. You can use print() to view them in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDlP4-zQ9WWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "east = {'date': datetime.datetime(2007, 4, 20, 0, 0), 'price': 1232443}\n",
        "west = {'date': datetime.datetime(2006, 5, 26, 0, 0), 'price': 1432673}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlRJg76E-TIQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bbcae498-c40e-4729-dcfb-a60b262ac152"
      },
      "source": [
        "print(f\"The price for a house in the east neighborhood was ${east['price']} in {east['date']:%m-%d-%Y}\")\n"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The price for a house in the east neighborhood was $1232443 in 04-20-2007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0iRAoI4AOrW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62733e91-0232-47ea-f119-4ff7ee010ec1"
      },
      "source": [
        "# Inside the f-string, access the values of the keys price and date in west dictionary. Format the date to month-day-year\n",
        "print(f\"The price for a house in the west neighborhood was ${west['price']} in {west['date']:%m-%d-%Y}.\")"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The price for a house in the west neighborhood was $1432673 in 05-26-2006.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TRBtQ4UA1tg",
        "colab_type": "text"
      },
      "source": [
        "# Preparing a report\n",
        "Once again, you scraped Wikipedia pages. This time, you searched for the description of useful tools used for text mining. Your first task is to prepare a report about different tools you found. You want to format the information contained in the dataset to be printed out as: The (tool) is a (description).\n",
        "\n",
        "In this case, template strings are the best solution to interpolate data generated by external sources into an already created template.\n",
        "\n",
        "For this example, the variables tool1, tool2 and tool3 contain three article titles. Each variable description1, description2 and description3 contains the corresponding article description.\n",
        "\n",
        "If you want to explore the variables, you can use print() to view them in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRR8zq1y9h04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tool1= 'Natural Language Toolkit'\n",
        "tool2 = 'TextBlob'\n",
        "tool3 = 'Gensim'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMHqG8-7Bev7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "description1 = 'suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.'\n",
        "description2 = 'Python library for processing textual data. It provides a simple API for diving into common natural language processing tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.'\n",
        "description3 =  'Gensim is a robust open-source vector space modeling and topic modeling toolkit implemented in Python. It uses NumPy, SciPy and optionally Cython for performance. Gensim is specifically designed to handle large text collections, using data streaming and efficient incremental algorithms, which differentiates it from most other scientific software packages that only target batch and in-memory processing.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziZcC3aUBthC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cda7299e-23cf-4a09-b1f0-1f193e475620"
      },
      "source": [
        "# Import Template\n",
        "from string import Template\n",
        "\n",
        "# Create a template\n",
        "wikipedia = Template(\"$tool is a $description\")\n",
        "\n",
        "# Substitute variables in template\n",
        "print(wikipedia.substitute(tool=tool1, description=description1))"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Natural Language Toolkit is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8yhOU9QBzIT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "278251a9-98e4-44ff-f928-f4d1f343d03d"
      },
      "source": [
        "print(wikipedia.substitute(tool=tool2, description=description2))"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TextBlob is a Python library for processing textual data. It provides a simple API for diving into common natural language processing tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny1nkHyYCDIr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bd8bd047-a666-460c-8fb1-26e0075247d8"
      },
      "source": [
        "print(wikipedia.substitute(tool=tool3, description=description3))"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gensim is a Gensim is a robust open-source vector space modeling and topic modeling toolkit implemented in Python. It uses NumPy, SciPy and optionally Cython for performance. Gensim is specifically designed to handle large text collections, using data streaming and efficient incremental algorithms, which differentiates it from most other scientific software packages that only target batch and in-memory processing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYtT23asCPo3",
        "colab_type": "text"
      },
      "source": [
        "# Identifying prices\n",
        "After you showed your report to your boss, he came up with the idea of offering courses to the company's users on some of the tools you studied. In order to make a pilot test, you will send an email offering a course about one of the tools, randomly chosen from your dataset. You also mention that the estimated fee needs to be paid on a monthly basis.\n",
        "\n",
        "For writing the email, you will use Template strings. You remember that you need to be careful when you use the dollar sign since it is used for identifiers in this case.\n",
        "\n",
        "For this example, the list tools contains the corresponding tool name, fee and payment type for the product offer. If you want to explore the variable, you can use print() to view it in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv7fXy24CUwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tools = ['Natural Language Toolkit', '20', 'month']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIb3i_saDNtv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30d70cbe-9c0e-426a-bc12-22fc11522453"
      },
      "source": [
        "# Import template\n",
        "from string import Template\n",
        "\n",
        "# Select variables\n",
        "our_tool = tools[0]\n",
        "our_fee = tools[1]\n",
        "our_pay = tools[2]\n",
        "\n",
        "# Create template\n",
        "course = Template(\"We are offering a 3-month beginner course on $tool just for $$ $fee ${pay}ly\")\n",
        "\n",
        "# Substitute identifiers with three variables\n",
        "print(course.substitute(tool=our_tool, fee=our_fee, pay=our_pay))"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We are offering a 3-month beginner course on Natural Language Toolkit just for $ 20 monthly\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcdoDFT7DZl_",
        "colab_type": "text"
      },
      "source": [
        "# Playing safe\n",
        "You are in charge of a new project! Your job is to start collecting information from the company's main application users. You will make an online quiz and ask your users to voluntarily answer two questions. However, it is not mandatory for the user to answer both. You will be handling user-provided strings so you decide to use the Template method to print the input information. This allows users to double-check their answers before submitting them.\n",
        "\n",
        "The answer of one user has been stored in the dictionary answers. You can use the print() function to view the variables in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD9abj3qDOoJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc9a96df-a958-4606-dc62-bab9f64d43b5"
      },
      "source": [
        "answers = {'answer1': 'I really like the app. But there are some features that can be improved'}\n",
        "\n",
        "# Import template\n",
        "from string import Template\n",
        "\n",
        "# Complete template string using identifiers\n",
        "the_answers = Template(\"Check your answer 1: $answer1, and your answer 2: $answer2\")\n",
        "\n",
        "# Use substitute to replace identifiers\n",
        "try:\n",
        "    print(the_answers.substitute(answers))\n",
        "except KeyError:\n",
        "    print(\"Missing information\")"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Missing information\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5DkRZJoEOzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29231ae6-f631-49ed-8b0a-46df48c7d85c"
      },
      "source": [
        "# Use safe_substitute to replace identifiers\n",
        "try:\n",
        "    print(the_answers.safe_substitute(answers))\n",
        "except KeyError:\n",
        "    print(\"Missing information\")"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check your answer 1: I really like the app. But there are some features that can be improved, and your answer 2: $answer2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYnmL9_dEsUo",
        "colab_type": "text"
      },
      "source": [
        "# Regular Expressions for Pattern Matching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVOW3n0HFXuv",
        "colab_type": "text"
      },
      "source": [
        "# Are they bots?\n",
        "The company that you are working for asked you to perform a sentiment analysis using a dataset with tweets. First of all, you need to do some cleaning and extract some information.\n",
        "While printing out some text, you realize that some tweets contain user mentions. Some of these mentions follow a very strange pattern. A few examples that you notice: @robot3!, @robot5& and @robot7#\n",
        "\n",
        "To analyze if those users are bots, you will do a proof of concept with one tweet and extract them using the .findall() method.\n",
        "\n",
        "You write down some helpful metacharacters to help you later:\n",
        "\n",
        "**\\d: digit**\n",
        "\n",
        "**\\w: word character**\n",
        "\n",
        "**\\W: non-word character**\n",
        "\n",
        "**\\s: whitespace**\n",
        "\n",
        "\n",
        "The text of one tweet was saved in the variable sentiment_analysis. You can use print(sentiment_analysis) to view it in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTiQPksUEdWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_analysis = '@robot9! @robot4& I have a good feeling that the show isgoing to be amazing! @robot9$ @robot7%'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bLHOR86Hg3P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad26d4d4-c00f-4588-9b76-f931472fdabe"
      },
      "source": [
        "# Import the re module\n",
        "import re\n",
        "\n",
        "# Write the regex\n",
        "regex = r\"@robot\\d\\W\"\n",
        "\n",
        "# Find all matches of regex\n",
        "print(re.findall(regex, sentiment_analysis))"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['@robot9!', '@robot4&', '@robot9$', '@robot7%']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1nWxuw-HyiR",
        "colab_type": "text"
      },
      "source": [
        "# Find the numbers\n",
        "While examining the tweet text in your dataset, you detect that some tweets carry extra information. The text contains the number of retweets, user mentions, and likes of that tweet. So, you decide to extract this important information.\n",
        "\n",
        "**The information is given as in this example:**\n",
        "\n",
        "**Agh...snow! User_mentions:9, likes: 5, number of retweets: 4**\n",
        "\n",
        "You also bring your list of metacharacters: **\\d digit**, **\\w word character**, **\\s whitespace.**\n",
        "\n",
        "The variable sentiment_analysis containing the text of one tweet and the re module were loaded in your session. You can use print() to view it in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM6LqMuKHiAJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5798cece-6650-4f24-efdd-bd5fe3f07df7"
      },
      "source": [
        "sentiment_analysis = \"Unfortunately one of those moments wasn't a giant squid monster. User_mentions:2, likes: 9, number of retweets: 7\"\n",
        "# Write a regex that matches the number of user mentions given as, for example, User_mentions:9 in sentiment_analysis\n",
        "print(re.findall(r\"User_mentions:\\d\", sentiment_analysis))"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['User_mentions:2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZIIadI6J78g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5913ba2-ce2f-4d4c-e0cd-15a0f5afbe51"
      },
      "source": [
        "# Write a regex that matches the number of likes given as, for example, likes: 5 in sentiment_analysis\n",
        "print(re.findall(r\"likes:\\s\\d\", sentiment_analysis))"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['likes: 9']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHmyN0iLKYUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2bf34b5-d5fc-4414-d905-0e935cf0f114"
      },
      "source": [
        "# Write a regex that matches the number of retweets given as, for example, number of retweets: 4 in sentiment_analysis\n",
        "print(re.findall(r\"number\\sof\\sretweets:\\s\\d\", sentiment_analysis))"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['number of retweets: 7']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS7LjzrxK9Ux",
        "colab_type": "text"
      },
      "source": [
        "# Match and split\n",
        "Some of the tweets in your dataset were downloaded incorrectly. Instead of having spaces to separate words, they have strange characters. You decide to use regular expressions to handle this situation. You print some of these tweets to understand which pattern you need to match.\n",
        "\n",
        "You notice that the sentences are always separated by a special character, followed by a number, the word break, and after that, another special character, e.g **&4break**!. The words are always separated by a special character, the word new, and a normal random character, e.g **#newH**.\n",
        "\n",
        "The variable sentiment_analysis containing the text of one tweet, as well as the re module were already loaded in your session. You can use print(sentiment_analysis) to view it in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxfTcayBM_-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60356eab-cd6c-4858-e216-0051ca050c77"
      },
      "source": [
        " sentiment_analysis = 'He#newHis%newTin love with$newPscrappy. #8break%He is&newYmissing him@newLalready'; sentiment_analysis"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'He#newHis%newTin love with$newPscrappy. #8break%He is&newYmissing him@newLalready'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX8hOcOOKw9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0d5a3e2-e667-41b8-f839-3ca27548e25f"
      },
      "source": [
        "# Write a regex that matches the pattern separating the sentences in sentiment_analysis, e.g. &4break!\n",
        "regex_sentence = r\"\\W\\dbreak\\W\"\n",
        "\n",
        "# Replace regex_sentence with a space \" \" in the variable sentiment_analysis. Assign it to sentiment_sub\n",
        "sentiment_sub = re.sub(regex_sentence, \" \", sentiment_analysis)\n",
        "\n",
        "# Write a regex that matches the pattern separating the words in sentiment_analysis, e.g. #newH\n",
        "regex_words = r\"\\Wnew\\w\"\n",
        "\n",
        "# Replace regex_words with a space in the variable sentiment_sub. Assign it to sentiment_final and print out the result.\n",
        "sentiment_final = re.sub(regex_words, \" \", sentiment_sub)\n",
        "print(sentiment_final)"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He is in love with scrappy.  He is missing him already\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBFsIVwVNTN2",
        "colab_type": "text"
      },
      "source": [
        "# Everything clean\n",
        "Back to your Twitter sentiment analysis project! There are several types of strings that increase your sentiment analysis complexity. But these strings do not provide any useful sentiment. Among them, we can have links and user mentions.\n",
        "\n",
        "In order to clean the tweets, you want to extract some examples first. You know that most of the times links start with http and do not contain any whitespace, e.g. https://www.datacamp.com. User mentions start with @ and can have letters and numbers only, e.g. @johnsmith3.\n",
        "\n",
        "You write down some helpful quantifiers to help you: * zero or more times, + once or more, ? zero or once.\n",
        "\n",
        "The list sentiment_analysis containing the text of three tweet are already loaded in your session. You can use print() to view the data in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRwU6t7eM3J8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict = {545: 'Boredd. Colddd @blueKnight39 Internet keeps stuffing up. Save me! https://www.tellyourstory.com',\n",
        " 546: \"I had a horrible nightmare last night @anitaLopez98 @MyredHat31 which affected my sleep, now I'm really tired\",\n",
        " 547: 'im lonely  keep me company @YourBestCompany! @foxRadio https://radio.foxnews.com 22 female, new york'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1XqykrWNtGJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c060a77b-c63d-4a34-fa16-170b85952391"
      },
      "source": [
        "sentiment_analysis = pd.Series(dict); sentiment_analysis"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "545    Boredd. Colddd @blueKnight39 Internet keeps st...\n",
              "546    I had a horrible nightmare last night @anitaLo...\n",
              "547    im lonely  keep me company @YourBestCompany! @...\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9G4HdFRNz-l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5ed119fa-523a-4c0f-f56b-da96909923c1"
      },
      "source": [
        "# Import re module\n",
        "import re\n",
        "\n",
        "# Write a regex to find all the matches of http links appearing in each tweet in sentiment_analysis. Print out the result.\n",
        "\n",
        "for tweet in sentiment_analysis:\n",
        "  # Write regex to match http links and print out result\n",
        "  print(re.findall(r\"http\\S+\", tweet))\n",
        "  # Write a regex to find all the matches of user mentions appearing in each tweet in sentiment_analysis. Print out the result.\n",
        "  # Write regex to match user mentions and print out result\n",
        "  print(re.findall(r\"@\\w+\", tweet))"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['https://www.tellyourstory.com']\n",
            "['@blueKnight39']\n",
            "[]\n",
            "['@anitaLopez98', '@MyredHat31']\n",
            "['https://radio.foxnews.com']\n",
            "['@YourBestCompany', '@foxRadio']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTQ-B5_rPW2O",
        "colab_type": "text"
      },
      "source": [
        "# Some time ago\n",
        "You are interested in knowing when the tweets were posted. After reading a little bit more, you learn that dates are provided in different ways. You decide to extract the dates using .findall() so you can normalize them afterwards to make them all look the same.\n",
        "\n",
        "You realize that the dates are always presented in one of the following ways:\n",
        "\n",
        "27 minutes ago\n",
        "\n",
        "4 hours ago\n",
        "\n",
        "23rd june 2018\n",
        "\n",
        "1st september 2019 17:25\n",
        "\n",
        "The list sentiment_analysis containing the text of three tweets, as well as the re module are already loaded in your session. You can use print() to view the data in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-xRa_8lvCCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict ={232: 'I would like to apologize for the repeated Video Games Live related tweets. 32 minutes ago',\n",
        " 233: '@zaydia but i cant figure out how to get there / back / pay for a hotel 1st May 2019',\n",
        " 234: 'FML: So much for seniority, bc of technological ineptness 23rd June 2018 17:54'}\n",
        "\n",
        "sentiment_analysis = pd.Series(dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIuiQuYmOrR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "01f0200a-1a35-4cba-d6b3-a3547a9336fd"
      },
      "source": [
        "# Complete the for-loop with a regex that finds all dates in a format similar to 27 minutes ago or 4 hours ago\n",
        "# Complete the for loop with a regex to find dates\n",
        "for date in sentiment_analysis:\n",
        "\tprint(re.findall(r\"\\d{1,2}\\s\\w+\\sago\", date))"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['32 minutes ago']\n",
            "[]\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZxt1znsv8KJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c7c02e4f-cd5e-4ab1-de48-e911ef35f642"
      },
      "source": [
        "# Complete the for-loop with a regex that finds all dates in a format similar to 23rd june 2018\n",
        "for date in sentiment_analysis:\n",
        "\tprint(re.findall(r\"\\d{1,2}\\w+\\s\\w+\\s\\d{4}\", date))"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "['1st May 2019']\n",
            "['23rd June 2018']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDU0WOCyOOBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "033a1b2f-6f62-4a3d-cd76-afdbc6e8332e"
      },
      "source": [
        "# Complete the for-loop with a regex that finds all dates in a format similar to 1st september 2019 17:25\n",
        "for date in sentiment_analysis:\n",
        "\tprint(re.findall(r\"\\d{1,2}\\w+\\s\\w+\\s\\d{4}\\s\\d{1,2}:\\d{2}\", date))"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "[]\n",
            "['23rd June 2018 17:54']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UynjDgFEwPu5",
        "colab_type": "text"
      },
      "source": [
        "# Getting tokens\n",
        "Your next step is to tokenize the text of your tweets. Tokenization is the process of breaking a string into lexical units or, in simpler terms, words. But first, you need to remove hashtags so they do not cloud your process. You realize that hashtags start with a # symbol and contain letters and numbers but never whitespace. After that, you plan to split the text at whitespace matches to get the tokens.\n",
        "\n",
        "You bring your list of quantifiers to help you: * zero o more times, + once or more, ? zero or once, {n, m} minimum n, maximum m.\n",
        "\n",
        "The variable sentiment_analysis containing the text of one tweet as well as the re module are already loaded in your session. You can use print(sentiment_analysis) to view it in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsxziHkzxCoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_analysis = 'ITS NOT ENOUGH TO SAY THAT IMISS U #MissYou #SoMuch #Friendship #Forever'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fXPG4qvwR9B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5deeb133-0508-449e-9ef2-bd422f3d8056"
      },
      "source": [
        "# Write a regex that matches the described hashtag pattern. Assign it to the regex variable.\n",
        "regex = r\"#\\w+\"\n",
        "\n",
        "# Replace all the matches of the regex with an empty string \"\". Assign it to no_hashtag variable\n",
        "no_hashtag = re.sub(regex, \"\", sentiment_analysis)\n",
        "\n",
        "# Split the text in the no_hashtag variable at every match of one or more consecutive whitespace.\n",
        "print(re.split(r\"\\s+\", no_hashtag))"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ITS', 'NOT', 'ENOUGH', 'TO', 'SAY', 'THAT', 'IMISS', 'U', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ8PjXuDxamo",
        "colab_type": "text"
      },
      "source": [
        "# Finding files\n",
        "You are not satisfied with your tweets dataset cleaning. There are still extra strings that do not provide any sentiment. Among them are strings refer to text file names.\n",
        "\n",
        "You also find a way to detect them:\n",
        "\n",
        "- They appear at the start of the string.\n",
        "- They always start with a sequence of 2 or 3 upper or lowercase vowels (a e i o u).\n",
        "- They always finish with the txt ending.\n",
        "\n",
        "You are not sure if you should remove them directly. So you write a script to find and store them in a separate dataset.\n",
        "\n",
        "You write down some metacharacters to help you: ^ anchor to beginning, . any character.\n",
        "\n",
        "The variable sentiment_analysis containing the text of two tweets as well as the re module are already loaded in your session. You can use print() to view it in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIz60o3QxJgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict = {780: 'AIshadowhunters.txt aaaaand back to my literature review. At least i have a friendly cup of coffee to keep me company',\n",
        " 781: \"ouMYTAXES.txt I am worried that I won't get my $900 even though I paid tax last year\"}\n",
        "\n",
        "sentiment_analysis =pd.Series(dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BC6X6qwyizx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d7c1f51c-f923-49a6-b40b-81e72501e78c"
      },
      "source": [
        "# Write a regex to match text file name\n",
        "regex = r\"^[aeiouAEIOU]{2,3}.+txt\"\n",
        "\n",
        "for text in sentiment_analysis:\n",
        "\t# Find all matches of the regex\n",
        "\tprint(re.findall(regex, text))\n",
        "    \n",
        "\t# Replace all matches with empty string\n",
        "\tprint(re.sub(regex, \"\", text))"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['AIshadowhunters.txt']\n",
            " aaaaand back to my literature review. At least i have a friendly cup of coffee to keep me company\n",
            "['ouMYTAXES.txt']\n",
            " I am worried that I won't get my $900 even though I paid tax last year\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-mwcg8LzFll",
        "colab_type": "text"
      },
      "source": [
        "# Give me your email\n",
        "A colleague has asked for your help! When a user signs up on the company website, they must provide a valid email address.\n",
        "The company puts some rules in place to verify that the given email address is valid:\n",
        "\n",
        "- The first part can contain:\n",
        " - Upper A-Z and lowercase letters a-z\n",
        " - Numbers\n",
        " - Characters: !, #, %, &, *, $, .\n",
        "- Must have @\n",
        "- Domain:\n",
        " - Can contain any word characters\n",
        " - But only .com ending is allowed\n",
        "The project consist of writing a script that checks if the email address follow the correct pattern. Your colleague gave you a list of email addresses as examples to test.\n",
        "\n",
        "The list emails as well as the re module are loaded in your session. You can use print(emails) to view the emails in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlLdvojvx6qI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emails= ['n.john.smith@gmail.com', '87victory@hotmail.com', '!#mary-=@msca.net']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgYf05p20aYx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2926e10d-cb3b-4129-f14e-3b35c70cf4ab"
      },
      "source": [
        "regex = r\"[A-Za-z0-9!#%&*\\$\\.]+@\\w+\\.com\"\n",
        "\n",
        "for example in emails:\n",
        "  \t# Match the regex to the string\n",
        "    if re.match(regex, example):\n",
        "        # Complete the format method to print out the result\n",
        "      \tprint(\"The email {email_example} is a valid email\".format(email_example=example))\n",
        "    else:\n",
        "      \tprint(\"The email {email_example} is invalid\".format(email_example=example)) "
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The email n.john.smith@gmail.com is a valid email\n",
            "The email 87victory@hotmail.com is a valid email\n",
            "The email !#mary-=@msca.net is invalid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HJSy0ls0tE6",
        "colab_type": "text"
      },
      "source": [
        "# Invalid password\n",
        "The second part of the website project is to write a script that validates the password entered by the user. The company also puts some rules in order to verify valid passwords:\n",
        "\n",
        "- It can contain lowercase a-z and uppercase letters A-Z\n",
        "- It can contain numbers\n",
        "- It can contain the symbols: *, #, $, %, !, &, .\n",
        "- It must be at least 8 characters long but not more than 20\n",
        "\n",
        "Your colleague also gave you a list of passwords as examples to test.\n",
        "\n",
        "The list passwords and the module re are loaded in your session. You can use print(passwords) to view them in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_OquMo00cKe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e0458e20-c050-4e3f-9033-b6018c5a7ee6"
      },
      "source": [
        "passwords= ['Apple34!rose', 'My87hou#4$', 'abc123']\n",
        "\n",
        "# Write a regex to match a valid password\n",
        "regex = r\"[a-zA-Z0-9!#%!&*\\$\\.]{8,20}\"\n",
        "\n",
        "for example in passwords:\n",
        "  \t# Scan the strings to find a match\n",
        "    if re.search(regex, example):\n",
        "        # Complete the format method to print out the result\n",
        "      \tprint(\"The password {pass_example} is a valid password\".format(pass_example=example))\n",
        "    else:\n",
        "      \tprint(\"The password {pass_example} is invalid\".format(pass_example=example))   "
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The password Apple34!rose is a valid password\n",
            "The password My87hou#4$ is a valid password\n",
            "The password abc123 is invalid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNbKiHBV1XO8",
        "colab_type": "text"
      },
      "source": [
        "# Understanding the difference\n",
        "You need to keep working and cleaning your tweets dataset. You realize that there are some HTML tags present. You need to remove them but keep the inside content as they are useful for analysis.\n",
        "\n",
        "Let's take a look at this sentence containing an HTML tag:\n",
        "\n",
        "*I want to see that <strong>amazing show</strong> again!.*\n",
        "\n",
        "You know that for getting HTML tag you need to match anything that sits inside angle brackets < >. But the biggest problem is that the closing tag has the same structure. If you match too much, you will end up removing key information. So you need to decide whether to use a greedy or a lazy quantifier.\n",
        "\n",
        "The string is already loaded as string to your session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbJyshPm1RvE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68461adb-559f-45ab-f72a-3d461d2aa418"
      },
      "source": [
        "string ='I want to see that <strong>amazing show</strong> again!'\n",
        "\n",
        "# Write a regex to eliminate tags\n",
        "string_notags = re.sub(r\"<.+?>\", \"\", string)\n",
        "\n",
        "# Print out the result\n",
        "print(string_notags)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I want to see that amazing show again!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlGCYtr22lrY",
        "colab_type": "text"
      },
      "source": [
        "# Greedy matching\n",
        "Next, you see that numbers still appear in the text of the tweets. So, you decide to find all of them.\n",
        "\n",
        "Let's imagine that you want to extract the number contained in the sentence I was born on April 24th. A lazy quantifier will make the regex return 2 and 4, because they will match as few characters as needed. However, a greedy quantifier will return the entire 24 due to its need to match as much as possible.\n",
        "\n",
        "The re module as well as the variable sentiment_analysis are already loaded in your session. You can use print(sentiment_analysis) to view it in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiIghllP2QBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_analysis= 'Was intending to finish editing my 536-page novel manuscript tonight, but that will probably not happen. And only 12 pages are left '"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81_6OjXO2yQ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "967dd4c5-b213-4320-d222-8c688f204604"
      },
      "source": [
        "# Use a lazy quantifier to match all numbers that appear in the variable sentiment_analysis\n",
        "numbers_found_lazy = re.findall(r\"\\d+?\", sentiment_analysis)\n",
        "\n",
        "# Print out the result\n",
        "print(numbers_found_lazy)"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['5', '3', '6', '1', '2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld_RXf4a4VGM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e37ca566-d204-451c-e2ab-cb748d6b00f5"
      },
      "source": [
        "# Now, use a greedy quantifier to match all numbers that appear in the variable sentiment_analysis\n",
        "numbers_found_greedy = re.findall(r\"\\d+\", sentiment_analysis)\n",
        "\n",
        "# Print out the result\n",
        "print(numbers_found_greedy)"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['536', '12']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTx1D6N14z0q",
        "colab_type": "text"
      },
      "source": [
        "# Lazy approach\n",
        "You have done some cleaning in your dataset but you are worried that there are sentences encased in parentheses that may cloud your analysis.\n",
        "\n",
        "Again, a greedy or a lazy quantifier may lead to different results.\n",
        "\n",
        "For example, if you want to extract a word starting with a and ending with e in the string I like apple pie, you may think that applying the greedy regex a.+e will return apple. However, your match will be apple pie. A way to overcome this is to make it lazy by using ? which will return apple.\n",
        "\n",
        "The re module and the variable sentiment_analysis are already loaded in your session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0tpB9-84qi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_analysis= \"Put vacation photos online (They were so cute) a few yrs ago. PC crashed, and now I forget the name of the site (I'm crying). \""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ0DIH715Ap_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0887f20f-2094-4e15-f986-cb8c576f6b28"
      },
      "source": [
        "# Use a greedy quantifier to match text that appears within parentheses in the variable sentiment_analysis\n",
        "sentences_found_greedy = re.findall(r\"\\(.*\\)\", sentiment_analysis)\n",
        "\n",
        "# Print out the result\n",
        "print(sentences_found_greedy)"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"(They were so cute) a few yrs ago. PC crashed, and now I forget the name of the site (I'm crying)\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XrNa28O5YmE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96ffbbc8-14fa-4d3f-a666-095e71632965"
      },
      "source": [
        "# Now, use a lazy quantifier to match text that appears within parentheses in the variable sentiment_analysis\n",
        "sentences_found_lazy = re.findall(r\"\\(.*?\\)\", sentiment_analysis)\n",
        "\n",
        "# Print out the results\n",
        "print(sentences_found_lazy)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['(They were so cute)', \"(I'm crying)\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RViYwGtO5u_l",
        "colab_type": "text"
      },
      "source": [
        "# Advanced Regular Expression Concepts\n",
        "\n",
        "# Try another name\n",
        "You are still working on your Twitter sentiment analysis. You analyze now some things that caught your attention. You noticed that there are email addresses inserted in some tweets. Now, you are curious to find out which is the most common name.\n",
        "\n",
        "You want to extract the first part of the email. E.g. if you have the email marysmith90@gmail.com, you are only interested in marysmith90.\n",
        "You need to match the entire expression. So you make sure to extract only names present in emails. Also, you are only interested in names containing upper (e.g. A,B, Z) or lowercase letters (e.g. a, d, z) and numbers.\n",
        "\n",
        "The list sentiment_analysis containing the text of three tweets as well as the re module were loaded in your session. You can use print() to view it in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9CGEnGy5gll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_analysis= ['Just got ur newsletter, those fares really are unbelievable. Write to statravelAU@gmail.com or statravelpo@hotmail.com. They have amazing prices',\n",
        " 'I should have paid more attention when we covered photoshop in my webpage design class in undergrad. Contact me Hollywoodheat34@msn.net.',\n",
        " 'hey missed ya at the meeting. Read your email! msdrama098@hotmail.com']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmQybyjX6DfM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "064b18c6-fe5e-46ba-a1bc-89a098f69b36"
      },
      "source": [
        "# Write a regex that matches email\n",
        "regex_email = r\"([A-Za-z0-9]+)@\\S+\"\n",
        "\n",
        "for tweet in sentiment_analysis:\n",
        "    # Find all matches of regex in each tweet\n",
        "    email_matched = re.findall(regex_email, tweet)\n",
        "\n",
        "    # Complete the format method to print the results\n",
        "    print(\"Lists of users found in this tweet: {}\".format(email_matched))"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lists of users found in this tweet: ['statravelAU', 'statravelpo']\n",
            "Lists of users found in this tweet: ['Hollywoodheat34']\n",
            "Lists of users found in this tweet: ['msdrama098']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwOOnLSN6xs-",
        "colab_type": "text"
      },
      "source": [
        "# Flying home\n",
        "Your boss assigned you to a small project. They are performing an analysis of the travels people made to attend business meetings. You are given a dataset with only the email subjects for each of the people traveling.\n",
        "\n",
        "You learn that the text followed a pattern. Here is an example:\n",
        "\n",
        "Here you have your boarding pass LA4214 AER-CDB 06NOV.\n",
        "\n",
        "You need to extract the information about the flight:\n",
        "\n",
        "- The two letters indicate the airline (e.g LA),\n",
        "- The 4 numbers are the flight number (e.g. 4214).\n",
        "- The three letters correspond to the departure (e.g AER),\n",
        "The destination (CDB),\n",
        "- The date (06NOV) of the flight.\n",
        "- All letters are always uppercase.\n",
        "\n",
        "The variable flight containing one email subject was loaded in your session. You can use print() to view it in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbNwayEX6Qxj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a18432b7-ca55-4756-ca33-1f483c6ee8cc"
      },
      "source": [
        "flight = 'Subject: You are now ready to fly. Here you have your boarding pass IB3723 AMS-MAD 06OCT'\n",
        "\n",
        "# Complete the regular expression to match and capture all the flight information required. Only the first parenthesis were placed for you.\n",
        "regex = r\"([A-Z]{2})(\\d{4})\\s([A-Z]{3})-([A-Z]{3})\\s(\\d{2}[A-Z]{3})\"\n",
        "\n",
        "# Find all the matches corresponding to each piece of information about the flight. Assign it to flight_matches.\n",
        "flight_matches = re.findall(regex, flight)\n",
        "\n",
        "# Complete the format method with the elements contained in flight_matches. In the first line print the airline,and the flight number. In the second line, the departure and destination. In the third line, the date.\n",
        "print(\"Airline: {} Flight number: {}\".format(flight_matches[0][0], flight_matches[0][1]))\n",
        "print(\"Departure: {} Destination: {}\".format(flight_matches[0][2], flight_matches[0][3]))\n",
        "print(\"Date: {}\".format(flight_matches[0][4]))\n"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Airline: IB Flight number: 3723\n",
            "Departure: AMS Destination: MAD\n",
            "Date: 06OCT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qikmK-rK_0t5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6D94hzH_8c5",
        "colab_type": "text"
      },
      "source": [
        "# Love it!\n",
        "You are still working on the Twitter sentiment analysis project. First, you want to identify positive tweets about movies and concerts.\n",
        "\n",
        "You plan to find all the sentences that contain the words love, like, or enjoy and capture that word. You will limit the tweets by focusing on those that contain the words movie or concert by keeping the word in another group. You will also save the movie or concert name.\n",
        "\n",
        "For example, if you have the sentence: I love the movie Avengers. You match and capture love. You need to match and capture movie. Afterwards, you match and capture anything until the dot.\n",
        "\n",
        "The list sentiment_analysis containing the text of three tweets and the re module are loaded in your session. You can use print() to view the data in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xbh_1D4f_-ZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4a7a1d87-7d11-4191-d1a2-0c2a63ef4dce"
      },
      "source": [
        "sentiment_analysis =['I totally love the concert The Book of Souls World Tour. It kinda amazing!',\n",
        " 'I enjoy the movie Wreck-It Ralph. I watched with my boyfriend.',\n",
        " \"I still like the movie Wish Upon a Star. Too bad Disney doesn't show it anymore.\"]\n",
        "\n",
        " \n",
        "# Write a regex that matches sentences with the optional words\n",
        "regex_positive = r\"(love|like|enjoy).+?(movie|concert)\\s(.+?)\\.\"\n",
        "\n",
        "for tweet in sentiment_analysis:\n",
        "\t# Find all matches of regex in tweet\n",
        "    positive_matches = re.findall(regex_positive, tweet)\n",
        "    \n",
        "    # Complete format to print out the results\n",
        "    print(\"Positive comments found {}\".format(positive_matches))"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive comments found [('love', 'concert', 'The Book of Souls World Tour')]\n",
            "Positive comments found [('enjoy', 'movie', 'Wreck-It Ralph')]\n",
            "Positive comments found [('like', 'movie', 'Wish Upon a Star')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWP_No_ZAaWD",
        "colab_type": "text"
      },
      "source": [
        "# Ugh! Not for me!\n",
        "After finding positive tweets, you want to do it for negative tweets. Your plan now is to find sentences that contain the words hate, dislike or disapprove. You will again save the movie or concert name. You will get the tweet containing the words movie or concert but this time, you don't plan to save the word.\n",
        "\n",
        "For example, if you have the sentence: I dislike the movie Avengers a lot.. You match and capture dislike. You will match but not capture the word movie. Afterwards, you match and capture anything until the dot.\n",
        "\n",
        "The list sentiment_analysis containing the text of three tweets as well as the re module are loaded in your session. You can use print() to view the data in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYaU8MmfAmcZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f2388ab1-2f7b-4634-ac9e-5a38446597f9"
      },
      "source": [
        "sentiment_analysis =['That was horrible! I really dislike the movie The cabin and the ant. So boring.',\n",
        " \"I disapprove the movie Honest with you. It's full of cliches.\",\n",
        " 'I dislike very much the concert After twelve Tour. The sound was horrible.']\n",
        "\n",
        "# Write a regex that matches sentences with the optional words\n",
        "regex_negative = r\"(hate|dislike|disapprove).+?(?:movie|concert)\\s(.+?)\\.\"\n",
        "\n",
        "for tweet in sentiment_analysis:\n",
        "\t# Find all matches of regex in tweet\n",
        "    negative_matches = re.findall(regex_negative, tweet)\n",
        "    \n",
        "    # Complete format to print out the results\n",
        "    print(\"Negative comments found {}\".format(negative_matches))"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative comments found [('dislike', 'The cabin and the ant')]\n",
            "Negative comments found [('disapprove', 'Honest with you')]\n",
            "Negative comments found [('dislike', 'After twelve Tour')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT5LxqQNBbpI",
        "colab_type": "text"
      },
      "source": [
        "# Parsing PDF files\n",
        "You now need to work on another small project you have been delaying. Your company gave you some PDF files of signed contracts. The goal of the project is to create a database with the information you parse from them. Three of these columns should correspond to the day, month, and year when the contract was signed.\n",
        "The dates appear as Signed on 05/24/2016 (05 indicating the month, 24 the day). You decide to use capturing groups to extract this information. Also, you would like to retrieve that information so you can store it separately in different variables.\n",
        "\n",
        "You decide to do a proof of concept.\n",
        "\n",
        "The variable contract containing the text of one contract and the re module are already loaded in your session. You can use print() to view the data in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy6vLpt1CAaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contract = 'Provider will invoice Client for Services performed within 30 days of performance.  Client will pay Provider as set forth in each Statement of Work within 30 days of receipt and acceptance of such invoice. It is understood that payments to Provider for services rendered shall be made in full as agreed, without any deductions for taxes of any kind whatsoever, in conformity with Providers status as an independent contractor. Signed on 03/25/2001.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhSTQA8IAcp3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "121ee234-ef75-4d50-96b6-352eba0d3975"
      },
      "source": [
        "# Write a regex that captures the month, day, and year in which the contract was signed. Scan contract for matches.\n",
        "regex_dates = r\"Signed\\son\\s(\\d{2})/(\\d{2})/(\\d{4})\"\n",
        "dates = re.search(regex_dates, contract)\n",
        "\n",
        "# Assign each captured group to the corresponding keys in the dictionary.\n",
        "signature = {\n",
        "\t\"day\": dates.group(2),\n",
        "\t\"month\": dates.group(1),\n",
        "\t\"year\": dates.group(3)\n",
        "}\n",
        "\n",
        "# Complete the f-string method to print out the captured groups. Use the values corresponding to each key in the dictionary.\n",
        "print(\"Our first contract is dated back to {data[year]}. Particularly, the day {data[day]} of the month {data[month]}.\".format(data=signature))"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our first contract is dated back to 2001. Particularly, the day 25 of the month 03.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aUlGjcTCqhn",
        "colab_type": "text"
      },
      "source": [
        "# Close the tag, please!\n",
        "In the meantime, you are working on one of your other projects. The company is going to develop a new product. It will help developers automatically check the code they are writing. You need to write a short script for checking that every HTML tag that is open has its proper closure.\n",
        "\n",
        "You have an example of a string containing HTML tags:\n",
        "\n",
        "<title>The Data Science Company</title>\n",
        "\n",
        "You learn that an opening HTML tag is always at the beginning of the string. It appears inside <>. A closing tag also appears inside <>, but it is preceded by /.\n",
        "\n",
        "You also remember that capturing groups can be referenced using numbers, e.g \\4.\n",
        "\n",
        "The list html_tags, containing three strings with HTML tags, and there module are loaded in your session. You can use print() to view the data in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf07rB2ZCG7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "html_tags = ['<body>Welcome to our course! It would be an awesome experience</body>',\n",
        " '<article>To be a data scientist, you need to have knowledge in statistics and mathematics</article>',\n",
        " '<nav>About me Links Contact me!']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbuyq8Z3DB1v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b1374a5c-0fe5-4de3-d2d4-b3ec72870a7c"
      },
      "source": [
        "for string in html_tags:\n",
        "    # Complete the regex and find if it matches a closed HTML tags\n",
        "    match_tag =  re.match(r\"<(\\w+)>.*?</\\1>\", string)\n",
        " \n",
        "    if match_tag:\n",
        "        # If it matches print the first group capture\n",
        "        print(\"Your tag {} is closed\".format(match_tag.group(1))) \n",
        "    else:\n",
        "        # If it doesn't match capture only the tag \n",
        "        notmatch_tag = re.match(r\"<(\\w+)>\", string)\n",
        "        # Print the first group capture\n",
        "        print(\"Close your {} tag!\".format(notmatch_tag.group(1)))"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your tag body is closed\n",
            "Your tag article is closed\n",
            "Close your nav tag!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGMg3x06DMIh",
        "colab_type": "text"
      },
      "source": [
        "# Reeepeated characters\n",
        "Back to your sentiment analysis! Your next task is to replace elongated words that appear in the tweets. We define an elongated word as a word that contains a repeating character twice or more times. e.g. \"Awesoooome\".\n",
        "\n",
        "Replacing those words is very important since a classifier will treat them as a different term from the source words lowering their frequency.\n",
        "\n",
        "To find them, you will use capturing groups and reference them back using numbers. E.g \\4.\n",
        "\n",
        "If you want to find a match for Awesoooome. You first need to capture Awes. Then, match o and reference the same character back, and then, me.\n",
        "\n",
        "The list sentiment_analysis, containing the text of three tweets, and the re module are loaded in your session. You can use print() to view the data in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki8448MDDGte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_analysis = ['@marykatherine_q i know! I heard it this morning and wondered the same thing. Moscooooooow is so behind the times',\n",
        " 'Staying at a friends house...neighborrrrrrrs are so loud-having a party',\n",
        " 'Just woke up an already have read some e-mail']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU4aixWpDb-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2a73e769-1fa3-472f-dc44-f23aa53ba008"
      },
      "source": [
        "# Complete the regex to match an elongated word\n",
        "regex_elongated = r\"\\w*(\\w)\\1\\w*\"\n",
        "\n",
        "for tweet in sentiment_analysis:\n",
        "\t# Find if there is a match in each tweet \n",
        "\tmatch_elongated = re.search(regex_elongated, tweet)\n",
        "    \n",
        "\tif match_elongated:\n",
        "\t\t# Assign the captured group zero \n",
        "\t\telongated_word = match_elongated.group(0)\n",
        "        \n",
        "\t\t# Complete the format method to print the word\n",
        "\t\tprint(\"Elongated word found: {word}\".format(word=elongated_word))\n",
        "\telse:\n",
        "\t\tprint(\"No elongated word found\")     \t"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elongated word found: Moscooooooow\n",
            "Elongated word found: neighborrrrrrrs\n",
            "No elongated word found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuoU5xBQEJGR",
        "colab_type": "text"
      },
      "source": [
        "# Surrounding words\n",
        "Now, you want to perform some visualizations with your sentiment_analysis dataset. You are interested in the words surrounding python. You want to count how many times a specific words appears right before and after it.\n",
        "\n",
        "Positive lookahead (?=) makes sure that first part of the expression is followed by the lookahead expression. Positive lookbehind (?<=) returns all matches that are preceded by the specified pattern.\n",
        "\n",
        "The variable sentiment_analysis, containing the text of one tweet, and the re module are loaded in your session. You can use print() to view the data in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jI46CJ6Df0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " sentiment_analysis = 'You need excellent python skills to be a data scientist. Must be! Excellent python'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTqrCQDrESKt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c111a472-8222-4a4f-fb66-ebcd2e384f5b"
      },
      "source": [
        "# Get all the words that are followed by the word python in sentiment_analysis. Print out the word found.\n",
        "look_ahead = re.findall(r\"\\w+(?=\\spython)\", sentiment_analysis)\n",
        "\n",
        "# Print out\n",
        "print(look_ahead)"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['excellent', 'Excellent']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muVYz2m0EY8Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f1b4350-e7a0-40b3-c734-2087e889ef0b"
      },
      "source": [
        "# Get all the words that are preceded by the word python or Python in sentiment_analysis. Print out the words found.\n",
        "look_behind = re.findall(r\"(?<=[Pp]ython\\s)\\w+\", sentiment_analysis)\n",
        "\n",
        "# Print out\n",
        "print(look_behind)"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['skills']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRFX1kNeFSyR",
        "colab_type": "text"
      },
      "source": [
        "# Filtering phone numbers\n",
        "Now, you need to write a script for a cell-phone searcher. It should scan a list of phone numbers and return those that meet certain characteristics.\n",
        "\n",
        "The phone numbers in the list have the structure:\n",
        "\n",
        "- Optional area code: 3 numbers\n",
        "- Prefix: 4 numbers\n",
        "- Line number: 6 numbers\n",
        "- Optional extension: 2 numbers\n",
        "E.g. 654-8764-439434-01.\n",
        "\n",
        "You decide to use .findall() and the non-capturing group's negative lookahead (?!) and negative lookbehind (?<!).\n",
        "\n",
        "The list cellphones, containing three phone numbers, and the re module are loaded in your session. You can use print() to view the data in the IPython Shell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilC9Xc5zEjRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3fd42e74-605d-4147-9162-63c6617322a4"
      },
      "source": [
        "cellphones= ['4564-646464-01', '345-5785-544245', '6476-579052-01']\n",
        "# Get all phone numbers that are not preceded by the optional area code.\n",
        "for phone in cellphones:\n",
        "\t# Get all phone numbers not preceded by area code\n",
        "\tnumber = re.findall(r\"(?<!\\d{3}-)\\d{4}-\\d{6}-\\d{2}\", phone)\n",
        "\tprint(number)\n"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['4564-646464-01']\n",
            "[]\n",
            "['6476-579052-01']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eepvf6dXJVNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ab129285-3576-4736-ef8c-683392563de0"
      },
      "source": [
        "# Get all the phone numbers that are not followed by the optional extension.\n",
        "for phone in cellphones:\n",
        "\t# Get all phone numbers not followed by optional extension\n",
        "\tnumber = re.findall(r\"\\d{3}-\\d{4}-\\d{6}(?!-\\d{2})\", phone)\n",
        "\tprint(number)"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "['345-5785-544245']\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}